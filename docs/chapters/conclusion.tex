We have constructed two new algorithms to solve sparse Einstein summation 
problems for tensor networks, one that generates SQL queries to solve Einsum 
problems and another one mapping the pairwise contraction operations into 
batch matrix multiplication with an efficient C++ backend. Our design shows 
significant improvements in solution for large and complex Einsum problems 
by utilizing sparse data structures along with their corresponding optimized 
strategies of computation. We have compared our methods through experiments 
against existing contraction algorithms, which show that they are very competitive, 
particularly for sparsity and computation time. We will further improve our 
C++ implementation and memory efficiency and include the ability to treat 
even larger tensor networks by higher-order contractions and denser tensors 
in the future.  