In this chapter we present two algorithms for performing Einstein summation. First,
we introduce our implementation of the four mapping rules developed in ``Efficient and Portable
Einstein Summation in SQL"~\cite{sql_einsum}, to generate SQL queries for solving Einsum problems.
This will serve as a baseline to compare other algorithms against. Second, we explain our C++
implementations with multiple levels of optimization. The underlying algorithm of the C++
implementations builds on Torch's strategy of mapping Einsum operations to a batch matrix
multiplication kernel. Both algorithms, namely the algorithm for the SQL implementation and
the algorithm used for the C++ versions, decompose large Einstein summation operations
into smaller, pairwise operations to exploit efficient contraction paths.

\section{The SQL Algorithm}
In this section, we present Blacher et al.'s~\cite{sql_einsum} algorithm and our
implementation of it for mapping format strings and the corresponding tensors to SQL,
enabling Einstein summation in databases. First, we introduce the portable schema for
representing tensors, specifically sparse tensors, in SQL. We then show their four mapping
rules to generate non-nested Einsum queries from arbitrary format strings. Finally, we
explain how we exploit efficient contraction paths by decomposing large Einsum queries
into smaller parts.

\subsection{Portable Schema for Tensors}
Blacher et al. chose the COO format to represent tensors as it only uses integers and
floating point numbers, which results in a vendor independent schema for encoding tensors
across various database management systems (DBMS). For example, a 3D tensor $A \in
    \mathbb{R}^{I \times J \times K}$ has the following schema:

\[
    A(i\ \ INT,\ \ j\ \ INT,\ \ k\ \ INT,\ \ val\ \ DOUBLE)
\]
%
Each tensor is stored in a separate table. In the example, table A stores a 3D tensor,
where each value ($val$) can be addressed by specifying the corresponding indices
($i$,~$j$,~$k$).

\subsection{Mapping Einstein Summation to SQL}
``Efficient and Portable Einstein Summation in SQL" introduces four rules for mapping
any tensor expression in Einstein notation to SQL.

\begin{description}
    \item \textbf{R1} All input tensors are enumerated in the FROM clause.
    \item \textbf{R2} The indices of the output tensor are enumerated in the SELECT clause
          and the GROUP BY clause.
    \item \textbf{R3} The new value is the SUM of all values multiplied together.
    \item \textbf{R4} Indices that are the same among input tensors are transitively equated
          in the WHERE clause.
\end{description}
%
Say we want to map the tensor operation given by $ik,k \rightarrow i$, a matrix-vector
multiplication, with tensors $A \in \mathbb{R}^{I \times K}$, $v \in \mathbb{R}^{K}$ and

\begin{equation*}
    A =
    \begin{bmatrix}
        0.0 & 1.0 \\
        0.0 & 0.0 \\
        5.0 & 0.0 \\
        0.0 & 0.0
    \end{bmatrix},
    \quad
    v =
    \begin{bmatrix}
        4.0 \\
        1.0
    \end{bmatrix}.
\end{equation*}
%
When applying all four rules to map the example tensor expression to SQL, we get the result
seen in Listing \ref{lst:einsum:sql}.

\begin{lstlisting}[caption={Einstein summation in SQL.}, captionpos={t}, label={lst:einsum:sql}]
    WITH A(i, j, val) AS (                          -- matrix A
        VALUES (0, 1, 1.0), (2, 0, 5.0)
    ), v(i, val) AS (                               -- vector v
        VALUES (0, 4.0), (1, 1.0)
    ) SELECT A.i AS i,                              -- R2
        SUM(A.val * v.val) AS val                   -- R3
      FROM A, v                                     -- R1
      WHERE A.j=v.i                                 -- R4
      GROUP BY A.i                                  -- R2
\end{lstlisting}
%
While all four rules are needed to ensure every possible Einstein summation problem
can be translated to SQL, for some tensor expressions the conditions to apply the rules
R2 and/or R4 are not fulfilled. If there are no indices after the arrow in the format
string, the output is scalar and does not require R2. Furthermore, if there are no common
indices among the input tensors, there is no summation in the tensor expression and R4
can be omitted. The rules guarantee a correct mapping, not a mapping with minimal code size.
Though requirering extra checks, in some cases the SQL queries could be simplified further.

\subsection{Optimizing Contraction Order}
Mapping a tensor expression directly into a single, non-nested SQL query in Einstein
notation is known to produce execution times that are far from optimal, especially for operations
involving many tensors. The inefficiency stems from the fact that conventional query optimizers
are unaware of the contraction order of the repeating indices within tensor expressions and are
therefore incapable of effectively breaking down the query into smaller parts to exploit efficient
contraction paths as described in the Background section \ref{sec:tensor:contractions}.\\
One can get around this using intermediate tensors via subqueries or common table expressions,
which decomposes one large Einstein summation query into smaller pieces and lets the database
engine follow a pre-defined contraction order. More precisely, using GROUP BY and SUM
aggregation in intermediate computations enforce query engines to evaluate the query in the
right order.

% TODO: Edit this section to list the right arguments for calling sql_einsum_query()
\section{Our Implementation of the SQL Algorithm}
We implemented the algorithm for mapping Einsum format strings to SQL queries proposed by Blacher
et al. in Python 3.11.0 as a small package, only requiring Numpy as a dependency. When
calling \textit{sql\_einsum\_query()}, an Einsum notation string, the tensor names, and the tensor
data have to be supplied. The path argument is optional. When not supplied with a path, an
optimized contraction path is calculated using cgreedy~\cite{cgreedy}. The cgreedy package
provides a greedy algorithm approach for finding an efficient contraction order for any given
format string and associated tensors, utilizing multiple cost functions. The construction of the
query is separated into two parts. The first part creates the tensors in COO format as SQL
compatible structures and returns the appropriate query. The second part applies the decomposition
schema, more precisely, it uses either the supplied or the calculated contraction path to build a
contraction list. The entries of the contraction list dictate the order and the exact pairwise
operations necessary to solve the Einstein summation problem. These subproblems are also specified
in Einstein notation. To build the second part of the query, we iterate the contraction list and
apply the four mapping rules explained in the previous section to assemble the correct SQL
strings for the given pairwise contractions. Finally, we merge the two generated query parts and
return the complete query.

\section{The C++ Algorithm}
Our method expands on Torch's strategy of mapping the Einstein summation problems to batch matrix
multiplication (BMM). We give an overview of our approach that pre-processes tensors for pairwise
operations, calculates the result via BMM and finally post-processes the result to fit the expected
output format. This separation of the computational parts into three distinct steps allows for the
simple application of the decomposition schema and enables independent debugging, measureing and
improveing of each section, while giving the benefit of readability. We will explain the sparse
BMM first to introduce the template that has to be followed by the pre-processing.

\subsection{Sparse BMM}
In order to achieve predictable computations with the BMM, we apply the template seen in Figure
\ref{fig:bmm:template}. The indices of the two input tensors are grouped as follows:

\begin{description}
    \item \textbf{Batch Indices.} All individual batch dimensions have to be combined into a single
          batch dimension.
    \item \textbf{Contracted Indices.} The dimensions to over which the contraction takes place.
    \item \textbf{Summed Left and Summed Right Indices.} All indices that only have a single occurence.
    \item \textbf{Kept Left and Kept Right Indices.} All indices and their dimensions that occur in only
          a single input tensor and in the output.
\end{description}
%
For our implementation we treat the removal of the S indices as part of the preprocessing. This means
the input tensors for our BMM have the following index groups: ...
% TODO: write the rest
\begin{center}
    \label{fig:bmm:template}
    \includegraphics[scale=0.7]{gray_bmm_indice_grouping.pdf}
\end{center}

\subsection{Pre-Processing}
The pre-processing phase of the algorithm is critical for aligning the tensors in Coordinate List
(COO) format with the requirements of batch matrix multiplication. This step involves some critical
steps to make sure that the tensors are correctly formatted and shaped for efficient computation.\\
First, the algorithm calculates appropriate format strings for COO tensors. These are important
since they will drive how the tensors are to be manipulated to obtain the correct structure as
specified by the contraction list. The format string should align with the requirements of the
desired contraction to ensure correctness and efficiency of the subsequent operation.\\
Besides computing the format strings, the algorithm computes the new shapes for the tensors.
In doing so, this step will need an assessment of the dimensions required to allow the BMM operation,
all while preserving the tensor operations. Precise computation of these new shapes is critical
to ensure that the tensors are aligned correctly for the contraction process.\\
These computed format strings are used in our algorithm to call our C++ single einsum function.
This function runs the einsum with the given format so that it can exactly manipulate the tensor
elements. At the same time, the new shapes are used to reshape the tensors via a call to the C++
reshape function. This is done to make the tensors comply with the dimensional requirements of BMM.\\
This pre-processing step will result in a COO tensor, which is optimally suited for batch matrix
multiplication. The complex einsum operations that align format and shape of tensors are performed
within the BMM framework to do the computation in an efficient and result-accurate way.

\subsection{Post-Processing}